{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\software\\Anaconda3\\envs\\python3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "E:\\software\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\software\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\software\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\software\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\software\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\software\\Anaconda3\\envs\\python3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import (VGG16, preprocess_input, decode_predictions)\n",
    "from keras.applications.vgg19 import (VGG19, preprocess_input, decode_predictions)\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.python.framework import ops\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "K.clear_session()\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def register_gradient():\n",
    "    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
    "        @ops.RegisterGradient(\"GuidedBackProp\")\n",
    "        def _GuidedBackProp(op, grad):\n",
    "            dtype = op.inputs[0].dtype\n",
    "            return grad * tf.cast(grad > 0., dtype) * \\\n",
    "                tf.cast(op.inputs[0] > 0., dtype)\n",
    "\n",
    "def deprocess_image(x):\n",
    "    '''\n",
    "    Same normalization as in:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "    '''\n",
    "    if np.ndim(x) > 3:\n",
    "        x = np.squeeze(x)\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "\n",
    "def grad_cam(model, x, category_index, layer_name):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "       model: model\n",
    "       x: image input\n",
    "       category_index: category index\n",
    "       layer_name: last convolution layer name\n",
    "    \"\"\"\n",
    "    # get category loss\n",
    "    class_output = model.output[:, category_index]\n",
    "\n",
    "    # layer output\n",
    "    convolution_output = model.get_layer(layer_name).output\n",
    "    # get gradients\n",
    "    grads = K.gradients(class_output, convolution_output)[0]\n",
    "    # get convolution output and gradients for input\n",
    "    gradient_function = K.function([model.input], [convolution_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([x])\n",
    "    output, grads_val = output[0], grads_val[0]\n",
    "\n",
    "    # avg\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "\n",
    "    # create heat map\n",
    "    cam = cv2.resize(cam, (x.shape[1], x.shape[2]), cv2.INTER_LINEAR)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "\n",
    "    # Return to BGR [0..255] from the preprocessed image\n",
    "    image_rgb = x[0, :]\n",
    "    image_rgb -= np.min(image_rgb)\n",
    "    image_rgb = np.minimum(image_rgb, 255)\n",
    "\n",
    "    cam = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "    cam = np.float32(cam) + np.float32(image_rgb)\n",
    "    cam = 255 * cam / np.max(cam)\n",
    "    return np.uint8(cam), heatmap\n",
    "\n",
    "def compile_saliency_function(model, activation_layer):\n",
    "    input_img = model.input\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    layer_output = layer_dict[activation_layer].output\n",
    "    max_output = K.max(layer_output, axis=3)\n",
    "    saliency = K.gradients(K.sum(max_output), input_img)[0]\n",
    "    return K.function([input_img, K.learning_phase()], [saliency])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_backprop(model, name):\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({'Relu': name}):\n",
    "\n",
    "        # get layers that have an activation\n",
    "        layer_dict = [layer for layer in model.layers[1:]\n",
    "                      if hasattr(layer, 'activation')]\n",
    "\n",
    "        # replace relu activation\n",
    "        for layer in layer_dict:\n",
    "            if layer.activation == keras.activations.relu:\n",
    "                layer.activation = tf.nn.relu\n",
    "\n",
    "        # re-instanciate a new model\n",
    "        new_model = VGG16(weights='imagenet')\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = np.load('./ImageNet/val_500.npy')\n",
    "y_val = np.load('./ImageNet/y_val_500.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = VGG19(weights='imagenet')\n",
    "model = VGG16(weights='imagenet')\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:142\n",
      "Predicted class:\n",
      "dowitcher (n02033041) with probability 0.92\n",
      "Predicted:142\n"
     ]
    }
   ],
   "source": [
    "img = x_val[97]\n",
    "print ('True:%d' % y_val[97])\n",
    "img4predict = np.expand_dims(img, axis=0)\n",
    "predictions = model.predict(img4predict)\n",
    "top_1 = decode_predictions(predictions)[0][0]\n",
    "print('Predicted class:')\n",
    "print('%s (%s) with probability %.2f' % (top_1[1], top_1[0], top_1[2]))\n",
    "\n",
    "predicted_class = np.argmax(predictions)\n",
    "cam_image, heat_map = grad_cam(model, img4predict, predicted_class, \"block5_pool\")\n",
    "print ('Predicted:%d' % predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "need_test = [0.05, 0.1, 0.2, 0.3, 0.4]\n",
    "for i in range(len(need_test)):\n",
    "    combineImg = cam_image * need_test[i] + img\n",
    "    cv2.imwrite('97-'+ str(need_test[i]) + '.JPEG', combineImg[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "register_gradient()\n",
    "guided_model = modify_backprop(model, 'GuidedBackProp')\n",
    "saliency_fn = compile_saliency_function(guided_model, \"block5_pool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "cv2.imwrite(\"gradcam.jpg\", cam_image)\n",
    "\n",
    "saliency = saliency_fn([img4predict, 0])\n",
    "grad_cam_img = saliency[0] * heat_map[..., np.newaxis]\n",
    "cv2.imwrite(\"guided_gradcam.jpg\", deprocess_image(grad_cam_img))\n",
    "print ('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#在图片上添字幕\n",
    "# guided grad_cam img\n",
    "saliency = saliency_fn([img4predict, 0])\n",
    "grad_cam_img = saliency[0] * heat_map[..., np.newaxis]\n",
    "\n",
    "# save img\n",
    "cam_image = cv2.resize(cam_image, (224, 224), cv2.INTER_LINEAR)\n",
    "cv2.putText(cam_image,str(top_1[1]), (20, 20), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1,(0, 0, 255))\n",
    "cv2.putText(cam_image,str(top_1[2]), (20, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1,(0, 0, 255))\n",
    "\n",
    "grad_cam_img = deprocess_image(grad_cam_img)\n",
    "grad_cam_img = cv2.resize(grad_cam_img, (224, 224), cv2.INTER_LINEAR)\n",
    "cv2.putText(grad_cam_img,str(top_1[1]), (20, 20), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1,(0, 0, 255))\n",
    "cv2.putText(grad_cam_img,str(top_1[2]), (20, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1,(0, 0, 255))\n",
    "\n",
    "cam_image = cam_image.astype('float32')\n",
    "grad_cam_img = grad_cam_img.astype('float32')\n",
    "im_h = cv2.hconcat([img[:,:,::-1], cam_image, grad_cam_img])\n",
    "cv2.imwrite('22.png', im_h)\n",
    "print ('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
